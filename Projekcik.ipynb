{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense # głęboko połączona warstwa przekazująca neurony dalej (batch, size)\n",
    "from tensorflow.keras.layers import Flatten # \"spłaszcza\" dane wejściowe, przekształca w 1wymiarową tablicę; nie wpływa na wielkość partii\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization #warstwa normalizująca dane wejściowe\n",
    "from tensorflow.keras.layers import Dropout # odrzuca część losową informacji, gdy sieć wyciąga za dużo informacji\n",
    "from tensorflow.keras.layers import LSTM # warstwa pamięci długookresowej (sztuczna rekurencyjna architektura sieci neuronowej RNN)\n",
    "from tensorflow.keras.models import Model # grupuje warstwy w obiekt z funkacjami uczenia i wnioskowania\n",
    "from tensorflow.keras.models import Sequential, load_model # do zaczytywania i wczytywania modelu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # tworzymy obiekt audio \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual # automatyczne tworzenie kontrolek interfejsu użytkownika  (user interface UI)\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.model_selection import train_test_split # dzielenie tablic lub macierzy na losowe podzbioru trenowania i testowania. \n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipywidgets import interactive\n",
    "from sklearn.metrics import r2_score # R2- współczynnik determinacji; funkcja oceny regresji \n",
    "from sklearn.metrics import mean_absolute_error #MAE oraz MSE (błędy)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler # przekształcanie cech skalując każdą z cech do określonego zakresu\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział zbioru danych na treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_to_lstm(predicted_variable_name, train_df, ratio):\n",
    "  dataset = train_df[predicted_variable_name].values #numpy.ndarray\n",
    "  dataset = dataset.astype('float32') #zamiana typu na float\n",
    "  dataset = np.reshape(dataset, (-1, 1)) #przekształcamy tablicę; wynikowa tablica ma tylko 1 kolumnę\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1)) #skalowanie zmiennych do postaci (0,1)\n",
    "  dataset = scaler.fit_transform(dataset) # wszystkie inne wartości są liniowo skalowane między tymi wartościami\n",
    "\n",
    "#podział uporządkowanego zestawu danych do trenowania i testowania.\n",
    "  train_size = int(len(dataset) * ratio)\n",
    "  test_size = len(dataset) - train_size\n",
    "  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "  return train, test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie zbioru danych LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back- liczba poprzednich kroków czasowych, które mają być użyte jako zmienne wejściowe do przewidywania następnego okresu czasu, w tym przypadku domyślnie 1.\n",
    "# scaler- normalizuje dane do zakresu (0,1)\n",
    "# tworzenie back(ów); konwersja tablicy wartości na macierz zestawu danych\n",
    "def create_dataset_lstm(dataset, look_back=1):   #look_back - wielkość kroku z którą testujemy dataset\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tworzymy i dopasowujemy model LSTM (zmiana batch_size). W poniższym modelu jest jedno wejście w warstwie wejściowej\n",
    "# i 10 neuronów w warstwie ukrytej. Warstwa wyjściowa przewiduje wartości\n",
    "def lstm_model(X_train, Y_train, X_test, Y_test, batch_size=20):\n",
    "  model = Sequential()  #liniowy stos warstw\n",
    "  model.add(LSTM(20, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "  model.add(Dropout(0.2)) \n",
    "  model.add(Dense(5))\n",
    "# definiujemy w czym będziemy wyrażać naszą jakość uczenia\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam') #definiujemy w czym będziemy wyrażać naszą jakośc uczenia\n",
    "\n",
    "# epochs - Funkcja aktywacji powtarzana jest 5 razy\n",
    "  history = model.fit(X_train, Y_train, epochs=5, batch_size=10, validation_data=(X_test, Y_test), \n",
    "                      # przerwij trenowanie, gdy monitorowana metryka przestanie się poprawiać\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=10)], verbose=1, shuffle=False)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model(model,X_train, X_test, Y_train, predicted_variable_name, testing=False):\n",
    "  dataset = train_df[predicted_variable_name].values #numpy.ndarray\n",
    "  dataset = dataset.astype('float32') #zamian typu na float\n",
    "  dataset = np.reshape(dataset, (-1, 1))  # zmienia shape na odwrotny (odwrócenie macierzy) nie w sposób ciągły (1 pod 2)\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  dataset = scaler.fit_transform(dataset)\n",
    "  \n",
    "#wykonaj prognozy\n",
    "  train_predict = model.predict(X_train)\n",
    "  test_predict = model.predict(X_test)\n",
    "\n",
    "#odwróć prognozy, przy obliczaniu błędu przekonwertujemy dane na tą samą jednostkę.  \n",
    "  train_predict = scaler.inverse_transform(train_predict)\n",
    "  Y_train = scaler.inverse_transform([Y_train])\n",
    "\n",
    "#oblicz średni kwadrat błędu\n",
    "  _mean_absolute_error = mean_absolute_error(Y_train[0], train_predict[:,0])   #jak mamy listę 13 elementów, to wstawiając [3,:] pobierze od 3 do 13 elementu\n",
    "  _mean_squared_error = np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0]))\n",
    "  print('Train Mean Absolute Error:', _mean_absolute_error)\n",
    "  print('Train Root Mean Squared Error:',_mean_squared_error)\n",
    "  if testing:\n",
    "    return Y_train, train_predict, _mean_absolute_error, _mean_squared_error\n",
    "  return Y_train, train_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja do wizualizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(Y_train, train_predict):\n",
    "  N = len(Y_train[0]) \n",
    "  aa=[x for x in range(N)]  # N oznacza liczbę cech w punkcie danych\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.plot(aa, Y_train[0], marker='.', label=\"actual\") # gdy . zmienimy na * to będziemy mieli zamiast . -> *\n",
    "  plt.plot(aa, train_predict[:,0], 'r', label=\"prediction\")\n",
    "  # plt.tick_params(left=False, labelleft=True) #remove ticks\n",
    "  plt.tight_layout()  # dostosuj dopełnienie między polamy pomocniczymi i wokół nich\n",
    "  sns.despine(top=True) # usuwamy grzbiet\n",
    "  plt.subplots_adjust(left=0.07)  # położenie lewej krawędzi wykresu\n",
    "  plt.title(\" prediction\")\n",
    "  plt.xlabel('Time step', size=15)  # rozmiar czcionki dla time step 15\n",
    "  plt.legend(fontsize=15)  # rozmiar czcionki elementów legendy\n",
    "  plt.show();  # uruchamiamy pętle zdarzeń, wyszukujemy wszystkie aktywne obiekty figur i otwieramy jedno lub więcej inteaktywnych okien.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import i scalenie danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data//eth_v_d.csv', index_col='Data')\n",
    "\n",
    "files=os.listdir('data/')\n",
    "files.remove('eth_v_d.csv')\n",
    "\n",
    "for file in files:\n",
    "  print(file+'\\n');\n",
    "  right = pd.read_csv('data/'+file, index_col='Data', engine='python')\n",
    "  main_table = data.merge(right=right, \n",
    "                                how = 'inner', \n",
    "                                left_index=True, \n",
    "                                right_index=True, \n",
    "                                copy=False, \n",
    "                                suffixes=('','_'+file[:-4]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Czyszczenie danych z pustych rekordów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dane przed usunięciem NaN:\", len(data), \"liczba kolumn: \", len(data.columns))\n",
    "data = data.dropna()\n",
    "print(\"Dane po usunięciu NaN:\", len(data), \"liczba kolumn: \", len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pierwsza liczba oznacza ilość wierszy, natomiast druga ilość kolumn w zbiorze danych\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zbiór treningowy\n",
    "ratio = 0.6  # współczynnik proporcji wymiarów (0.6 w stosunku do całego zbioru danych)\n",
    "N = int(len(data)*ratio)   # liczba próbek na klasę\n",
    "train_df, test_df = data[:N], data[N:]   # przypisanie próbek do zmiennych\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zbiór testowy\n",
    "ratio = 0.5\n",
    "N = int(len(data)*ratio)\n",
    "test_df, val_df = test_df[:N], test_df[N:]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podsumowanie statystyk odnoszących się do kolumny DataFrame \n",
    "# ta funkcja podaje wartości średnie, standardowe i odstęp międzykwartylowy\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapewnia obliczania w oknie kroczącym\n",
    "# windows = rozmiar ruchomego okna, jest to liczba obserwacji użytych do obliczenia statystyki \n",
    "# każde okno będzie miało stały rozmiar\n",
    "rolling = data.rolling(window=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wskazanie zmiennej do predycji\n",
    "data_roll = pd.DataFrame()\n",
    "data_roll['Zamkniecie']=train_df['Zamkniecie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(lw=(1, 100))\n",
    "def plot(lw):\n",
    "  rolling = data.rolling(window=lw, center=True)\n",
    "  data_roll = pd.DataFrame()\n",
    " \n",
    "  data_roll['Zamkniecie']=data['Zamkniecie']\n",
    "  data_roll['7 days rolling_mean(srednia kroczaca)']=data_roll['Zamkniecie'].rolling(lw, min_periods=1).mean()\n",
    "  ax = data_roll.plot(style=['-', '--'], rot=90, figsize=(20, 10)) \n",
    "  ax.lines[0].set_alpha(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wywołanie metody przygotowującej model pod LSTM\n",
    "predicted_variable_name = \"Zamkniecie\"\n",
    "train, test, scaler = prepare_dataset_to_lstm(predicted_variable_name, train_df, ratio=0.8) #scaler - normalizuje dane do zakresu (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowanie zestawów uczących i testowych do modelowania\n",
    "look_back = 20\n",
    "X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "\n",
    "#Przeszktałcenie DataFrame-u do modelu\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uczenie modelu\n",
    "history = lstm_model(X_train, Y_train, X_test, Y_test, batch_size=10)\n",
    "\n",
    "# loss - funkcja straty na zbiorze treningowym\n",
    "# val_loss - funkcja straty na zbiorze walidacyjnym (im mniejsza tym lepiej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis modelu sieci neuronowej w formacie JSON\n",
    "model_json = history.to_json()  #zapisanie modelu history do JSON\n",
    "with open(\"model.json\", \"w\") as json_file:  #utworzenie pliku model.json w trybie edycji i zatrzymanie w zmiennej json_file\n",
    "    json_file.write(model_json)\n",
    "# zapisanie wagi z modelu za pomocą funkcji save.weights. \n",
    "history.save_weights(\"model.h5\")  #wagi są zapisywane w pliku model.h5 w katalogu lokalnym.\n",
    "print(\"Saved model to disk\")  #komentarz udanej operacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, train_predict = evaluation_model(history,X_train, X_test, Y_train, predicted_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na wykresie dane nie są znormalizowane\n",
    "visualization(Y_train, train_predict) # niebieska- z csv wiersze i do nich wartości z pliku excel; czerwone- dla poszczegolnych wierszy błędy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponowny podział na zbiory treningowy i walidacyjny\n",
    "train, test, scaler = prepare_dataset_to_lstm(predicted_variable_name, train_df, ratio=0.8)\n",
    "\n",
    "look_back = 3 \n",
    "X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wielkość próbki\n",
    "batch_start, batch_end = 30, 40\n",
    "look_backs = [3,10,30]\n",
    "\n",
    "\n",
    "error_look_back = {}\n",
    "for look_back in look_backs:\n",
    "  MAEs = []\n",
    "  MSEs = []\n",
    "  Y_trains = []\n",
    "  train_predicts = []\n",
    "\n",
    "  X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "  X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "  for batch in range(batch_start, batch_end):\n",
    "    print(f'-------------------------------{batch}--------------------------')\n",
    "    history = lstm_model(X_train, Y_train, X_test, Y_test, batch_size=batch)\n",
    "    tmp_Y_train, tmp_train_predict, MAE, MSE  = evaluation_model(history,X_train, X_test, Y_train, predicted_variable_name, testing=True)\n",
    "    \n",
    "    MAEs.append(MAE)\n",
    "    MSEs.append(MSE)\n",
    "    Y_trains.append(tmp_Y_train)\n",
    "    train_predicts.append(tmp_train_predict)\n",
    "  error_look_back[look_back] = {\"MAE\":MAEs, \"MSE\":MSEs, \"Y_trains\": Y_trains, \"train_predicts\": train_predicts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_look_back[3][\"MSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_look_back[3][\"MAE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres błędów MSE oraz MAE\n",
    "look_back_to_check = 3 \n",
    "sns.lineplot(x=[a for a in range(batch_start, batch_end)], y=error_look_back[look_back_to_check][\"MSE\"])\n",
    "sns.lineplot(x=[a for a in range(batch_start, batch_end)], y=error_look_back[look_back_to_check][\"MAE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = 6\n",
    "look_back_to_check = 3\n",
    "visualization(Y_train = error_look_back[look_back_to_check][\"Y_trains\"][batch_index], train_predict = error_look_back[look_back_to_check][\"train_predicts\"][batch_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_look_back[3][\"Y_trains\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
