{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalacja potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5MHCQeDAUd3X",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (7.6.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: jupyter-client in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: backcall in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.17.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.17)\n",
      "Requirement already satisfied: decorator in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.0.6)\n",
      "Requirement already satisfied: parso>=0.7.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: wcwidth in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: nbconvert in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.0.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: defusedxml in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: testpath in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: h5py in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: six in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (3.15.8)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\anaconda\\envs\\zml_ztbd\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importowanie wymaganych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z4nn0PkVUlJp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-51366c088fea>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mipywidgets\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minteractive\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m \u001B[1;31m# dzielenie tablic lub macierzy na losowe podzbioru trenowania i testowania.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mipywidgets\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minteract\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minteract_manual\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mipywidgets\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minteractive\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense # głęboko połączona warstwa przekazująca neurony dalej (batch, size)\n",
    "from tensorflow.keras.layers import Flatten # \"spłaszcza\" dane wejściowe, przekształca w 1wymiarową tablicę; nie wpływa na wielkość partii\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization #warstwa normalizująca dane wejściowe\n",
    "from tensorflow.keras.layers import Dropout # odrzuca część losową informacji, gdy sieć wyciąga za dużo informacji\n",
    "from tensorflow.keras.layers import LSTM # warstwa pamięci długookresowej (sztuczna rekurencyjna architektura sieci neuronowej RNN)\n",
    "from tensorflow.keras.models import Model # grupuje warstwy w obiekt z funkacjami uczenia i wnioskowania\n",
    "from tensorflow.keras.models import Sequential, load_model # do zaczytywania i wczytywania modelu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # tworzymy obiekt audio \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual # automatyczne tworzenie kontrolek interfejsu użytkownika  (user interface UI)\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.model_selection import train_test_split # dzielenie tablic lub macierzy na losowe podzbioru trenowania i testowania. \n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipywidgets import interactive\n",
    "from sklearn.metrics import r2_score # R2- współczynnik determinacji; funkcja oceny regresji \n",
    "from sklearn.metrics import mean_absolute_error #MAE oraz MSE (błędy)\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import bibliotek do stworzenia sieci LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler # przekształcanie cech skalując każdą z cech do określonego zakresu\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping # przerywa trenowanie, gdy monitorowana metryka przestanie się poprawiać; \n",
    "                                          # estymator ten skaluje i tłumaczy każdą cechę indywidualnie tak, że znajduje się ona w zadanym zakresie na zbiorze uczącym (np. między 0 a 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie bazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNXhr96tUzag"
   },
   "outputs": [],
   "source": [
    "# katalog z plikiem powinien się znajdować w tym samym folderze, co obecnie odpalony plik\n",
    "data = pd.read_csv('./zmienne/usdpln_d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F28mhURdVfUZ"
   },
   "source": [
    "### Podzial na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pierwsza liczba oznacza ilość wierszy, natomiast druga ilość kolumn w zbiorze danych\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVIFFmksVtX7"
   },
   "outputs": [],
   "source": [
    "# zbiór treningowy\n",
    "ratio = 0.6  # współczynnik proporcji wymiarów (0.6 w stosunku do całego zbioru danych)\n",
    "N = int(len(data)*ratio)   # liczba próbek na klasę\n",
    "train_df, test_df = data[:N], data[N:]   # przypisanie próbek do zmiennych\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0jVcRkvWVDV"
   },
   "outputs": [],
   "source": [
    "# zbiór testowy\n",
    "ratio = 0.5\n",
    "N = int(len(data)*ratio)\n",
    "test_df, val_df = test_df[:N], test_df[N:]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "yxOZAIQgWjaW",
    "outputId": "2035dbd2-676d-4d86-bb4d-a2b2b91cb9c1"
   },
   "outputs": [],
   "source": [
    "# funkcja oblicza podsumowanie statystyk odnoszących się do kolumny DataFrame. \n",
    "# ta funkcja podaje wartości średnie, standardowe i odstęp międzykwartylowy.\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrtXH7VgWqsD"
   },
   "outputs": [],
   "source": [
    "# zapewnia obliczania w oknie kroczącym. \n",
    "# windows = rozmiar ruchomego okna, jest to liczba obserwacji użytych do obliczenia statystyki. \n",
    "# każde okno będzie miało stały rozmiar.\n",
    "rolling = data.rolling(window=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaOjWnf3WuAB"
   },
   "outputs": [],
   "source": [
    "# definiujemy nasz y, który chcemy przewidzieć; trenujemy model tylko na \"Zamkniecie\"\n",
    "data_roll = pd.DataFrame()\n",
    "data_roll['Zamkniecie']=train_df['Zamkniecie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(lw=(1, 100))  #wstawia suwak do ręcznego wywoływania funkcji. Nie ma potrzeby uruchamiać za każdym razem kod, gdy zmieniamy wartość. \n",
    "def plot(lw):\n",
    "  rolling = data.rolling(window=lw, center=True)\n",
    "  data_roll = pd.DataFrame()\n",
    " \n",
    "  data_roll['Zamkniecie']=data['Zamkniecie']\n",
    "  data_roll['7 days rolling_mean(srednia kroczaca)']=data_roll['Zamkniecie'].rolling(lw, min_periods=1).mean()\n",
    "  ax = data_roll.plot(style=['-', '--'], rot=90, figsize=(20, 10)) #odpowiada za rozmiar wykresu, oraz styl linii\n",
    "  ax.lines[0].set_alpha(0.3)   #zmienia przeźroczystość linii wskazującej \"Zamknięcie\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eSGFce8W3jD"
   },
   "source": [
    "### Przygotowanie danych do uczenia na sieci LSTM (zmiana wymiarow macierzy, by model zaczal obrabiac dane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4v22vMBXlIn"
   },
   "outputs": [],
   "source": [
    "zmienna_przewidywana = \"Zamkniecie\"\n",
    "\n",
    "def prepare_dataset_to_lstm(zmienna_przewidywana, train_df, ratio):\n",
    "  dataset = train_df[zmienna_przewidywana].values #numpy.ndarray\n",
    "  dataset = dataset.astype('float32') #zamiana typu na float\n",
    "  dataset = np.reshape(dataset, (-1, 1)) #przekształcamy tablicę; wynikowa tablica ma tylko 1 kolumnę\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1)) #skalowanie zmiennych do postaci (0,1)\n",
    "  dataset = scaler.fit_transform(dataset) # wszystkie inne wartości są liniowo skalowane między tymi wartościami\n",
    "\n",
    "#dzielimy uporządkowany zestaw danych do trenowania i testowania. Oblicza index punktu podziału i rozdziela dane na zestawy szkoleniowe z test. obserwacji, których można użyć do trenowania modelu, pozostawiając pozostałe do przetestowania\n",
    "  train_size = int(len(dataset) * ratio)\n",
    "  test_size = len(dataset) - train_size\n",
    "  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "  return train, test, scaler\n",
    "\n",
    "#uruchamiany tą funkcję z wyżej, przygotowanie modelu pod LSTM\n",
    "train, test, scaler = prepare_dataset_to_lstm(zmienna_przewidywana, train_df, ratio=0.8) #scaler - skaluje dane do zakresu 0, 1 (tak zwana normalizacja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPKKHxCWXpe1"
   },
   "outputs": [],
   "source": [
    "# look_back- liczba poprzednich kroków czasowych, które mają być użyte jako zmienne wejściowe do przewidywania następnego okresu czasu, w tym przypadku domyślnie 1.\n",
    "# scaler- skaluje dane do zakresu 0,1 (normalizacja)\n",
    "# tworzenie back(ów); konwertujemy tablicę wartości na macierz zestawu danych\n",
    "def create_dataset_lstm(dataset, look_back=1):   #look_back - wielkość kroku z którą testujemy dataset\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1): # żeby nie wyszło poza zasięg\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "#używamy funkcji by przygotować zestaw i przetestować zestawy danych do modelowania.\n",
    "look_back = 20 #liczba probek ktora pobieramy, minimalnie jedna próbka, maksymalnie tyle, ile ma ciąg elementów\n",
    "X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "\n",
    "#Zmienia kształt wejścia na próbki, kroki czasowe, cechy,\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu0pQXiDZYM7"
   },
   "source": [
    "## Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24NO3QG3Y7Pp"
   },
   "outputs": [],
   "source": [
    "#Tworzymy i dopasowujemy model LSTM (zmiana batch_size). W poniższym modelu jest jedno wejście w warstwie wejściowej\n",
    "# i 10 neuronów w warstwie ukrytej. Warstwa wyjściowa przewiduje wartości\n",
    "def lstm_model(X_train, Y_train, X_test, Y_test, batch_size=20):\n",
    "  model = Sequential()  #liniowy stos warstw\n",
    "  model.add(LSTM(20, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "  model.add(Dropout(0.2)) \n",
    "  model.add(Dense(8))\n",
    "# definiujemy w czym będziemy wyrażać naszą jakość uczenia\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam') #definiujemy w czym będziemy wyrażać naszą jakośc uczenia\n",
    "\n",
    "# epochs - Funkcja aktywacji powtarzana jest 5 razy\n",
    "  history = model.fit(X_train, Y_train, epochs=5, batch_size=10, validation_data=(X_test, Y_test), \n",
    "                      # przerwij trenowanie, gdy monitorowana metryka przestanie się poprawiać\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=10)], verbose=1, shuffle=False)\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OKDU7BRZhqQ"
   },
   "outputs": [],
   "source": [
    "#ewaluacja modelu\n",
    "def evaluation_model(model,X_train, X_test, Y_train, testing=False):\n",
    "  dataset = train_df[zmienna_przewidywana].values #numpy.ndarray\n",
    "  dataset = dataset.astype('float32') #zamian typu na float\n",
    "  dataset = np.reshape(dataset, (-1, 1))  # zmienia shape na odwrotny (odwrócenie macierzy) nie w sposób ciągły (1 pod 2)\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  dataset = scaler.fit_transform(dataset)\n",
    "  \n",
    "#wykonaj prognozy\n",
    "  train_predict = model.predict(X_train)\n",
    "  test_predict = model.predict(X_test)\n",
    "\n",
    "#odwróć prognozy, przy obliczaniu błędu przekonwertujemy dane na tą samą jednostkę.  \n",
    "  train_predict = scaler.inverse_transform(train_predict)\n",
    "  Y_train = scaler.inverse_transform([Y_train])\n",
    "\n",
    "#oblicz średni kwadrat błędu\n",
    "  _mean_absolute_error = mean_absolute_error(Y_train[0], train_predict[:,0])   #jak mamy listę 13 elementów, to wstawiając [3,:] pobierze od 3 do 13 elementu\n",
    "  _mean_squared_error = np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0]))\n",
    "  print('Train Mean Absolute Error:', _mean_absolute_error)\n",
    "  print('Train Root Mean Squared Error:',_mean_squared_error)\n",
    "  if testing:\n",
    "    return Y_train, train_predict, _mean_absolute_error, _mean_squared_error\n",
    "  return Y_train, train_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiujQG_iduIb",
    "outputId": "e8ecb3e7-9e2c-42e0-d29d-2736de0eea21"
   },
   "outputs": [],
   "source": [
    "def a():\n",
    "    return 1, 2, (10, 20)\n",
    "\n",
    "x,y, error = a()\n",
    "print(a())\n",
    "print(x,y, error)\n",
    "\n",
    "# 1 to nasz x- Y_train, 2 nasz y- train_predict  a (10-_mean_absolute_error, 20- _mean_squared_error) nasze dołożone errory (patrz analogicznie linijkę wyżej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgXynbpvZ_ZT",
    "outputId": "ec57cf4d-18cc-4236-f361-49e61e3a58e3"
   },
   "outputs": [],
   "source": [
    "#Model się uczy!\n",
    "history = lstm_model(X_train, Y_train, X_test, Y_test, batch_size=10)\n",
    "\n",
    "# loss to funkcja straty na zbiorze treningowym\n",
    "# val_loss to funkcja straty na zbiorze walidacyjnym (im mniejsza tym lepiej)\n",
    "\n",
    "# widzimy że z każdą kolejną epoką te dwa błędy są coraz mniejsze- zatem model dobrze się uczy. \n",
    "# im mniejsze błędy (bliższe 0- tym lepiej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBRLWe2tal_k",
    "outputId": "070f9856-1d3e-4d33-d48d-04dcd7883e31"
   },
   "outputs": [],
   "source": [
    "# zapisujemy model sieci neuronowej w formacie JSON\n",
    "model_json = history.to_json()  #zapisanie modelu history do JSON\n",
    "with open(\"model.json\", \"w\") as json_file:  #utwórz plik model.json w trybie edycji i zatrzymaj w zmiennej json_file\n",
    "    json_file.write(model_json)\n",
    "# zapisanie wagi z modelu za pomocą funkcji save.weights. \n",
    "history.save_weights(\"model.h5\")  #wagi są zapisywane w pliku model.h5 w katalogu lokalnym.\n",
    "print(\"Saved model to disk\")  #komentarz udanej operacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfuK6w9caHN8",
    "outputId": "bc323c82-f312-43d0-904a-0d75540a2fe7"
   },
   "outputs": [],
   "source": [
    "\n",
    "evaluation_model(history,X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFznAylEdG8X",
    "outputId": "3bad9dad-673c-4318-84e6-7780371beeec"
   },
   "outputs": [],
   "source": [
    "Y_train, train_predict = evaluation_model(history,X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ-5nMYZcgXv"
   },
   "outputs": [],
   "source": [
    "def visualization(Y_train, train_predict):\n",
    "  N = len(Y_train[0]) \n",
    "  aa=[x for x in range(N)]  # N oznacza liczbę cech w punkcie danych\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.plot(aa, Y_train[0], marker='.', label=\"actual\") # gdy . zmienimy na * to będziemy mieli zamiast . -> *\n",
    "  plt.plot(aa, train_predict[:,0], 'r', label=\"prediction\")\n",
    "  # plt.tick_params(left=False, labelleft=True) #remove ticks\n",
    "  plt.tight_layout()  # dostosuj dopełnienie między polamy pomocniczymi i wokół nich\n",
    "  sns.despine(top=True) # usuwamy grzbiet\n",
    "  plt.subplots_adjust(left=0.07)  # położenie lewej krawędzi wykresu\n",
    "  plt.title(\" prediction\")\n",
    "  plt.xlabel('Time step', size=15)  # rozmiar czcionki dla time step 15\n",
    "  plt.legend(fontsize=15)  # rozmiar czcionki elementów legendy\n",
    "  plt.show();  # uruchamiamy pętle zdarzeń, wyszukujemy wszystkie aktywne obiekty figur i otwieramy jedno lub więcej inteaktywnych okien.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "2QEN7oeKc4W-",
    "outputId": "a989d390-23a5-457e-b2fb-2b9fcbf02502"
   },
   "outputs": [],
   "source": [
    "# Na wykresie dane nie są znormalizowane\n",
    "visualization(Y_train, train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "186VBDTrd3yn"
   },
   "source": [
    "## Zmieniamy wielkosc batch, by zobaczyc jaki wplyw ma ta zmienna na wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RAuJONqejpj"
   },
   "outputs": [],
   "source": [
    "# <odswiezam dane>, gdyz wymiary danych testowych i treningowych przestaja sie zgadac\n",
    "train, test, scaler = prepare_dataset_to_lstm(zmienna_przewidywana, train_df, ratio=0.8)\n",
    "\n",
    "def create_dataset_lstm(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "    \n",
    "look_back = 3 #liczba probek ktora pobieramy, minimalnie jedna probka, maksymalnie tyle, ile ma ciag elementow\n",
    "X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "print(X_test)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RB4mp_3neAns",
    "outputId": "ab46fbc9-e979-4b84-cb4e-8b84231039a7"
   },
   "outputs": [],
   "source": [
    "# wielkosc batchu [10, 20, 50]\n",
    "batch_start, batch_end = 30, 40 # od do\n",
    "look_backs = [3,10,30] # takie look backi sprawdzamy i potem do nich mozemy wykresy zrobic\n",
    "\n",
    "\n",
    "error_look_back = {}\n",
    "for look_back in look_backs:\n",
    "  MAEs = []\n",
    "  MSEs = []\n",
    "  Y_trains = []\n",
    "  train_predicts = []\n",
    "\n",
    "  X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "  X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "  for batch in range(batch_start, batch_end):\n",
    "    print(f'-------------------------------{batch}--------------------------')\n",
    "    history = lstm_model(X_train, Y_train, X_test, Y_test, batch_size=batch)\n",
    "    tmp_Y_train, tmp_train_predict, MAE, MSE  = evaluation_model(history,X_train, X_test, Y_train, testing=True)\n",
    "    \n",
    "    MAEs.append(MAE)\n",
    "    MSEs.append(MSE)\n",
    "    Y_trains.append(tmp_Y_train)\n",
    "    train_predicts.append(tmp_train_predict)\n",
    "  error_look_back[look_back] = {\"MAE\":MAEs, \"MSE\":MSEs, \"Y_trains\": Y_trains, \"train_predicts\": train_predicts}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wraz ze wzrostem batch'a, pogorszaja sie na wyniki - MAE i MSE idealnie powinny rownac sie zero, wiec generalnie im mniejsze ich wartosci, tym model uwazamy za lepszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNeu-weeMnsY",
    "outputId": "ea51694e-87b0-405c-b663-c25a18f6436c"
   },
   "outputs": [],
   "source": [
    "# wyświetlenie liczby kolumn i wierszy\n",
    "train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_look_back[3][\"MSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVFzpdz8NCvZ",
    "outputId": "0aa11263-a0ac-442a-a05e-328bd45d4164"
   },
   "outputs": [],
   "source": [
    "# wyświetlenie i posortowanie MSE\n",
    "MSEs.sort()\n",
    "print(MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "IDLSfMoeSYIJ",
    "outputId": "aa9a1c45-fdc7-4ecf-8da5-9b9e3ea686f0"
   },
   "outputs": [],
   "source": [
    "# wykres kreśli linię MSE, oraz MAE\n",
    "look_back_to_check = 3\n",
    "sns.lineplot(x=[a for a in range(batch_start, batch_end)], y=error_look_back[look_back_to_check][\"MSE\"])\n",
    "sns.lineplot(x=[a for a in range(batch_start, batch_end)], y=error_look_back[look_back_to_check][\"MAE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "FKkdbS5adpp3",
    "outputId": "5655fbf0-6246-42fb-9256-5c700bcdae0b"
   },
   "outputs": [],
   "source": [
    "batch_index = 6 # to znaczy batch_start (bedzie tyle indexow ile jest od batch_start do batch_end)\n",
    "look_back_to_check = 3\n",
    "visualization(Y_train = error_look_back[look_back_to_check][\"Y_trains\"][batch_index], train_predict = error_look_back[look_back_to_check][\"train_predicts\"][batch_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fC3jQGyaeOHF",
    "outputId": "a54537d7-a14f-4a06-e1b9-44ae407596c6"
   },
   "outputs": [],
   "source": [
    "error_look_back[3][\"Y_trains\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of testowanie_modelu_agata.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}