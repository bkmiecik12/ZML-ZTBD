{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalacja potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5MHCQeDAUd3X",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install ipywidgets #interaktywne widżety HTML dla notebooków Jupyter i jądra IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importowanie wymaganych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z4nn0PkVUlJp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense # głęboko połączona warstwa przekazująca neurony dalej (batch, size)\n",
    "from tensorflow.keras.layers import Flatten # \"spłaszcza\" dane wejściowe, przekształca w 1wymiarową tablicę; nie wpływa na wielkość partii\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization #warstwa normalizująca dane wejściowe\n",
    "from tensorflow.keras.layers import Dropout # odrzuca część losową informacji, gdy sieć wyciąga za dużo informacji\n",
    "from tensorflow.keras.layers import LSTM # warstwa pamięci długookresowej (sztuczna rekurencyjna architektura sieci neuronowej RNN)\n",
    "from tensorflow.keras.models import Model # grupuje warstwy w obiekt z funkacjami uczenia i wnioskowania\n",
    "from tensorflow.keras.models import Sequential, load_model # do zaczytywania i wczytywania modelu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # tworzymy obiekt audio \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual # automatyczne tworzenie kontrolek interfejsu użytkownika  (user interface UI)\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.model_selection import train_test_split # dzielenie tablic lub macierzy na losowe podzbioru trenowania i testowania. \n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipywidgets import interactive\n",
    "from sklearn.metrics import r2_score # R2- współczynnik determinacji; funkcja oceny regresji \n",
    "from sklearn.metrics import mean_absolute_error #MAE oraz MSE (błędy)\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import bibliotek do stworzenia sieci LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler # przekształcanie cech skalując każdą z cech do określonego zakresu\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping # przerywa trenowanie, gdy monitorowana metryka przestanie się poprawiać; \n",
    "                                          # estymator ten skaluje i tłumaczy każdą cechę indywidualnie tak, że znajduje się ona w zadanym zakresie na zbiorze uczącym (np. między 0 a 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie bazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xNXhr96tUzag"
   },
   "outputs": [],
   "source": [
    "# katalog z plikiem powinien się znajdować w tym samym folderze, co obecnie odpalony plik\n",
    "data = pd.read_csv('./data/eth_v_d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F28mhURdVfUZ"
   },
   "source": [
    "### Podzial na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2072, 5)\n"
     ]
    }
   ],
   "source": [
    "# pierwsza liczba oznacza ilość wierszy, natomiast druga ilość kolumn w zbiorze danych\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tVIFFmksVtX7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1243, 5)\n"
     ]
    }
   ],
   "source": [
    "# zbiór treningowy\n",
    "ratio = 0.6  # współczynnik proporcji wymiarów (0.6 w stosunku do całego zbioru danych)\n",
    "N = int(len(data)*ratio)   # liczba próbek na klasę\n",
    "train_df, test_df = data[:N], data[N:]   # przypisanie próbek do zmiennych\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b0jVcRkvWVDV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829, 5)\n"
     ]
    }
   ],
   "source": [
    "# zbiór testowy\n",
    "ratio = 0.5\n",
    "N = int(len(data)*ratio)\n",
    "test_df, val_df = test_df[:N], test_df[N:]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "yxOZAIQgWjaW",
    "outputId": "2035dbd2-676d-4d86-bb4d-a2b2b91cb9c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Otwarcie</th>\n",
       "      <th>Najwyzszy</th>\n",
       "      <th>Najnizszy</th>\n",
       "      <th>Zamkniecie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1243.000000</td>\n",
       "      <td>1243.000000</td>\n",
       "      <td>1243.000000</td>\n",
       "      <td>1243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>209.190909</td>\n",
       "      <td>218.160156</td>\n",
       "      <td>198.442360</td>\n",
       "      <td>209.302651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>272.820407</td>\n",
       "      <td>285.257570</td>\n",
       "      <td>257.265208</td>\n",
       "      <td>272.770696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.471900</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.075000</td>\n",
       "      <td>10.565000</td>\n",
       "      <td>9.655000</td>\n",
       "      <td>10.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.090000</td>\n",
       "      <td>52.220000</td>\n",
       "      <td>48.450000</td>\n",
       "      <td>50.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>313.885000</td>\n",
       "      <td>324.735000</td>\n",
       "      <td>300.190000</td>\n",
       "      <td>313.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1385.020000</td>\n",
       "      <td>1422.860000</td>\n",
       "      <td>1271.070000</td>\n",
       "      <td>1385.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Otwarcie    Najwyzszy    Najnizszy   Zamkniecie\n",
       "count  1243.000000  1243.000000  1243.000000  1243.000000\n",
       "mean    209.190909   218.160156   198.442360   209.302651\n",
       "std     272.820407   285.257570   257.265208   272.770696\n",
       "min       0.420000     0.471900     0.411000     0.420000\n",
       "25%      10.075000    10.565000     9.655000    10.090000\n",
       "50%      50.090000    52.220000    48.450000    50.250000\n",
       "75%     313.885000   324.735000   300.190000   313.885000\n",
       "max    1385.020000  1422.860000  1271.070000  1385.020000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# funkcja oblicza podsumowanie statystyk odnoszących się do kolumny DataFrame. \n",
    "# ta funkcja podaje wartości średnie, standardowe i odstęp międzykwartylowy.\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HrtXH7VgWqsD"
   },
   "outputs": [],
   "source": [
    "# zapewnia obliczania w oknie kroczącym. \n",
    "# windows = rozmiar ruchomego okna, jest to liczba obserwacji użytych do obliczenia statystyki. \n",
    "# każde okno będzie miało stały rozmiar.\n",
    "rolling = data.rolling(window=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IaOjWnf3WuAB"
   },
   "outputs": [],
   "source": [
    "# definiujemy nasz y, który chcemy przewidzieć; trenujemy model tylko na \"Zamkniecie\"\n",
    "data_roll = pd.DataFrame()\n",
    "data_roll['Zamkniecie']=train_df['Zamkniecie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f10a0f3911d438280b2c56650dfce0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='lw', min=1), Button(description='Run Interact', style=B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(lw=(1, 100))  #wstawia suwak do ręcznego wywoływania funkcji. Nie ma potrzeby uruchamiać za każdym razem kod, gdy zmieniamy wartość. \n",
    "def plot(lw):\n",
    "  rolling = data.rolling(window=lw, center=True)\n",
    "  data_roll = pd.DataFrame()\n",
    " \n",
    "  data_roll['Zamkniecie']=data['Zamkniecie']\n",
    "  data_roll['7 days rolling_mean(srednia kroczaca)']=data_roll['Zamkniecie'].rolling(lw, min_periods=1).mean()\n",
    "  ax = data_roll.plot(style=['-', '--'], rot=90, figsize=(20, 10)) #odpowiada za rozmiar wykresu, oraz styl linii\n",
    "  ax.lines[0].set_alpha(0.3)   #zmienia przeźroczystość linii wskazującej \"Zamknięcie\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eSGFce8W3jD"
   },
   "source": [
    "### Przygotowanie danych do uczenia na sieci LSTM (zmiana wymiarow macierzy, by model zaczal obrabiac dane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e4v22vMBXlIn"
   },
   "outputs": [],
   "source": [
    "zmienna_przewidywana = \"Zamkniecie\"\n",
    "\n",
    "def prepare_dataset_to_lstm(zmienna_przewidywana, train_df, ratio):\n",
    "  dataset = train_df[zmienna_przewidywana].values #numpy.ndarray\n",
    "  dataset = dataset.astype('float32') #zamiana typu na float\n",
    "  dataset = np.reshape(dataset, (-1, 1)) #przekształcamy tablicę; wynikowa tablica ma tylko 1 kolumnę\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1)) #skalowanie zmiennych do postaci (0,1)\n",
    "  dataset = scaler.fit_transform(dataset) # wszystkie inne wartości są liniowo skalowane między tymi wartościami\n",
    "\n",
    "#dzielimy uporządkowany zestaw danych do trenowania i testowania. Oblicza index punktu podziału i rozdziela dane na zestawy szkoleniowe z test. obserwacji, których można użyć do trenowania modelu, pozostawiając pozostałe do przetestowania\n",
    "  train_size = int(len(dataset) * ratio)\n",
    "  test_size = len(dataset) - train_size\n",
    "  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "  return train, test, scaler\n",
    "\n",
    "#uruchamiany tą funkcję z wyżej, przygotowanie modelu pod LSTM\n",
    "train, test, scaler = prepare_dataset_to_lstm(zmienna_przewidywana, train_df, ratio=0.8) #scaler - skaluje dane do zakresu 0, 1 (tak zwana normalizacja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BPKKHxCWXpe1"
   },
   "outputs": [],
   "source": [
    "# look_back- liczba poprzednich kroków czasowych, które mają być użyte jako zmienne wejściowe do przewidywania następnego okresu czasu, w tym przypadku domyślnie 1.\n",
    "# scaler- skaluje dane do zakresu 0,1 (normalizacja)\n",
    "# tworzenie back(ów); konwertujemy tablicę wartości na macierz zestawu danych\n",
    "def create_dataset_lstm(dataset, look_back=1):   #look_back - wielkość kroku z którą testujemy dataset\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1): # żeby nie wyszło poza zasięg\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "#używamy funkcji by przygotować zestaw i przetestować zestawy danych do modelowania.\n",
    "look_back = 20 #liczba probek ktora pobieramy, minimalnie jedna próbka, maksymalnie tyle, ile ma ciąg elementów\n",
    "X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "\n",
    "#Zmienia kształt wejścia na próbki, kroki czasowe, cechy,\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu0pQXiDZYM7"
   },
   "source": [
    "## Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "24NO3QG3Y7Pp"
   },
   "outputs": [],
   "source": [
    "#Tworzymy i dopasowujemy model LSTM (zmiana batch_size). W poniższym modelu jest jedno wejście w warstwie wejściowej\n",
    "# i 10 neuronów w warstwie ukrytej. Warstwa wyjściowa przewiduje wartości\n",
    "def lstm_model(X_train, Y_train, X_test, Y_test, batch_size=20):\n",
    "  model = Sequential()  #liniowy stos warstw\n",
    "  model.add(LSTM(20, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "  model.add(Dropout(0.2)) \n",
    "  model.add(Dense(5))\n",
    "# definiujemy w czym będziemy wyrażać naszą jakość uczenia\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam') #definiujemy w czym będziemy wyrażać naszą jakośc uczenia\n",
    "\n",
    "# epochs - Funkcja aktywacji powtarzana jest 5 razy\n",
    "  history = model.fit(X_train, Y_train, epochs=5, batch_size=10, validation_data=(X_test, Y_test), \n",
    "                      # przerwij trenowanie, gdy monitorowana metryka przestanie się poprawiać\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=10)], verbose=1, shuffle=False)\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7OKDU7BRZhqQ"
   },
   "outputs": [],
   "source": [
    "#ewaluacja modelu\n",
    "def evaluation_model(model,X_train, X_test, Y_train, testing=False):\n",
    "  dataset = train_df[zmienna_przewidywana].values #numpy.ndarray\n",
    "  dataset = dataset.astype('float32') #zamian typu na float\n",
    "  dataset = np.reshape(dataset, (-1, 1))  # zmienia shape na odwrotny (odwrócenie macierzy) nie w sposób ciągły (1 pod 2)\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  dataset = scaler.fit_transform(dataset)\n",
    "  \n",
    "#wykonaj prognozy\n",
    "  train_predict = model.predict(X_train)\n",
    "  test_predict = model.predict(X_test)\n",
    "\n",
    "#odwróć prognozy, przy obliczaniu błędu przekonwertujemy dane na tą samą jednostkę.  \n",
    "  train_predict = scaler.inverse_transform(train_predict)\n",
    "  Y_train = scaler.inverse_transform([Y_train])\n",
    "\n",
    "#oblicz średni kwadrat błędu\n",
    "  _mean_absolute_error = mean_absolute_error(Y_train[0], train_predict[:,0])   #jak mamy listę 13 elementów, to wstawiając [3,:] pobierze od 3 do 13 elementu\n",
    "  _mean_squared_error = np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0]))\n",
    "  print('Train Mean Absolute Error:', _mean_absolute_error)\n",
    "  print('Train Root Mean Squared Error:',_mean_squared_error)\n",
    "  if testing:\n",
    "    return Y_train, train_predict, _mean_absolute_error, _mean_squared_error\n",
    "  return Y_train, train_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiujQG_iduIb",
    "outputId": "e8ecb3e7-9e2c-42e0-d29d-2736de0eea21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, (10, 20))\n",
      "1 2 (10, 20)\n"
     ]
    }
   ],
   "source": [
    "def a():\n",
    "    return 1, 2, (10, 20)\n",
    "\n",
    "x,y, error = a()\n",
    "print(a())\n",
    "print(x,y, error)\n",
    "\n",
    "# 1 to nasz x- Y_train, 2 nasz y- train_predict  a (10-_mean_absolute_error, 20- _mean_squared_error) nasze dołożone errory (patrz analogicznie linijkę wyżej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgXynbpvZ_ZT",
    "outputId": "ec57cf4d-18cc-4236-f361-49e61e3a58e3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "#Model się uczy!\n",
    "history = lstm_model(X_train, Y_train, X_test, Y_test, batch_size=10)\n",
    "\n",
    "# loss to funkcja straty na zbiorze treningowym\n",
    "# val_loss to funkcja straty na zbiorze walidacyjnym (im mniejsza tym lepiej)\n",
    "\n",
    "# widzimy że z każdą kolejną epoką te dwa błędy są coraz mniejsze- zatem model dobrze się uczy. \n",
    "# im mniejsze błędy (bliższe 0- tym lepiej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBRLWe2tal_k",
    "outputId": "070f9856-1d3e-4d33-d48d-04dcd7883e31",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# zapisujemy model sieci neuronowej w formacie JSON\n",
    "model_json = history.to_json()  #zapisanie modelu history do JSON\n",
    "with open(\"model.json\", \"w\") as json_file:  #utwórz plik model.json w trybie edycji i zatrzymaj w zmiennej json_file\n",
    "    json_file.write(model_json)\n",
    "# zapisanie wagi z modelu za pomocą funkcji save.weights. \n",
    "history.save_weights(\"model.h5\")  #wagi są zapisywane w pliku model.h5 w katalogu lokalnym.\n",
    "print(\"Saved model to disk\")  #komentarz udanej operacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfuK6w9caHN8",
    "outputId": "bc323c82-f312-43d0-904a-0d75540a2fe7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "evaluation_model(history,X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFznAylEdG8X",
    "outputId": "3bad9dad-673c-4318-84e6-7780371beeec",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Y_train, train_predict = evaluation_model(history,X_train, X_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ-5nMYZcgXv",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def visualization(Y_train, train_predict):\n",
    "  N = len(Y_train[0]) \n",
    "  aa=[x for x in range(N)]  # N oznacza liczbę cech w punkcie danych\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.plot(aa, Y_train[0], marker='.', label=\"actual\") # gdy . zmienimy na * to będziemy mieli zamiast . -> *\n",
    "  plt.plot(aa, train_predict[:,0], 'r', label=\"prediction\")\n",
    "  # plt.tick_params(left=False, labelleft=True) #remove ticks\n",
    "  plt.tight_layout()  # dostosuj dopełnienie między polamy pomocniczymi i wokół nich\n",
    "  sns.despine(top=True) # usuwamy grzbiet\n",
    "  plt.subplots_adjust(left=0.07)  # położenie lewej krawędzi wykresu\n",
    "  plt.title(\" prediction\")\n",
    "  plt.xlabel('Time step', size=15)  # rozmiar czcionki dla time step 15\n",
    "  plt.legend(fontsize=15)  # rozmiar czcionki elementów legendy\n",
    "  plt.show();  # uruchamiamy pętle zdarzeń, wyszukujemy wszystkie aktywne obiekty figur i otwieramy jedno lub więcej inteaktywnych okien.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "2QEN7oeKc4W-",
    "outputId": "a989d390-23a5-457e-b2fb-2b9fcbf02502",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Na wykresie dane nie są znormalizowane\n",
    "visualization(Y_train, train_predict) # niebieska- z csv wiersze i do nich wartości z pliku excel (na podstawie ratio nie cale 2849 tylko 0.6 z tego); czerwone- dla poszczegolnych wierszy błędy; model dobrze się uczy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "186VBDTrd3yn"
   },
   "source": [
    "## Zmieniamy wielkosc batch, by zobaczyc jaki wplyw ma ta zmienna na wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RAuJONqejpj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# <odswiezam dane>, gdyz wymiary danych testowych i treningowych przestaja sie zgadac\n",
    "train, test, scaler = prepare_dataset_to_lstm(zmienna_przewidywana, train_df, ratio=0.8)\n",
    "\n",
    "def create_dataset_lstm(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "    \n",
    "look_back = 3 #liczba probek ktora pobieramy, minimalnie jedna probka, maksymalnie tyle, ile ma ciag elementow\n",
    "X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "print(X_test)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RB4mp_3neAns",
    "outputId": "ab46fbc9-e979-4b84-cb4e-8b84231039a7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# wielkosc batchu [10, 20, 50]\n",
    "batch_start, batch_end = 30, 40 # od do\n",
    "look_backs = [3,10,30] # takie look backi sprawdzamy i potem do nich mozemy wykresy zrobic\n",
    "\n",
    "\n",
    "error_look_back = {}\n",
    "for look_back in look_backs:\n",
    "  MAEs = []\n",
    "  MSEs = []\n",
    "  Y_trains = []\n",
    "  train_predicts = []\n",
    "\n",
    "  X_train, Y_train = create_dataset_lstm(train, look_back)\n",
    "  X_test, Y_test = create_dataset_lstm(test, look_back)\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "  for batch in range(batch_start, batch_end):\n",
    "    print(f'-------------------------------{batch}--------------------------')\n",
    "    history = lstm_model(X_train, Y_train, X_test, Y_test, batch_size=batch)\n",
    "    tmp_Y_train, tmp_train_predict, MAE, MSE  = evaluation_model(history,X_train, X_test, Y_train, testing=True)\n",
    "    \n",
    "    MAEs.append(MAE)\n",
    "    MSEs.append(MSE)\n",
    "    Y_trains.append(tmp_Y_train)\n",
    "    train_predicts.append(tmp_train_predict)\n",
    "  error_look_back[look_back] = {\"MAE\":MAEs, \"MSE\":MSEs, \"Y_trains\": Y_trains, \"train_predicts\": train_predicts}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wraz ze wzrostem batch'a, pogorszaja sie na wyniki - MAE i MSE idealnie powinny rownac sie zero, wiec generalnie im mniejsze ich wartosci, tym model uwazamy za lepszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNeu-weeMnsY",
    "outputId": "ea51694e-87b0-405c-b663-c25a18f6436c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# wyświetlenie liczby kolumn i wierszy; 2849:1346= 2,1 , a więc 20% (a wcześniej ratio 0.8), więc tak przyjął; model treningowy z predykcją (czerwona linia na wykresie)\n",
    "train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "error_look_back[3][\"MSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "error_look_back[3][\"MAE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVFzpdz8NCvZ",
    "outputId": "0aa11263-a0ac-442a-a05e-328bd45d4164",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# wyświetlenie i posortowanie MSE\n",
    "MSEs.sort()\n",
    "print(MSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "IDLSfMoeSYIJ",
    "outputId": "aa9a1c45-fdc7-4ecf-8da5-9b9e3ea686f0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# wykres kreśli linię MSE, oraz MAE\n",
    "look_back_to_check = 3 \n",
    "sns.lineplot(x=[a for a in range(batch_start, batch_end)], y=error_look_back[look_back_to_check][\"MSE\"])\n",
    "sns.lineplot(x=[a for a in range(batch_start, batch_end)], y=error_look_back[look_back_to_check][\"MAE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "FKkdbS5adpp3",
    "outputId": "5655fbf0-6246-42fb-9256-5c700bcdae0b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_index = 6 # to znaczy batch_start (bedzie tyle indexow ile jest od batch_start do batch_end)\n",
    "look_back_to_check = 3 #jak to wyrzucimy, to tez bedzie dzialac\n",
    "visualization(Y_train = error_look_back[look_back_to_check][\"Y_trains\"][batch_index], train_predict = error_look_back[look_back_to_check][\"train_predicts\"][batch_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fC3jQGyaeOHF",
    "outputId": "a54537d7-a14f-4a06-e1b9-44ae407596c6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "error_look_back[3][\"Y_trains\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of testowanie_modelu_agata.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}